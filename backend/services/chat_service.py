"""
Chat service layer
Handles business logic for conversation creation, message sending, streaming output, etc.

This file adds explicit command-triggered Agent integration based on the original ChatService.
When users send messages starting with `/task `, the backend will create and start Agent tasks (asynchronous execution),
and immediately return task creation confirmation in the chat. Task execution and progress are handled by the existing agents.manager,
the frontend can view task status and results through events or Agent API.
"""

import asyncio
import base64
import json
import os
import re
import textwrap
import uuid
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

# Agent task manager
from agents.manager import task_manager
from core.db import get_db
from core.events import emit_chat_message_chunk
from core.logger import get_logger
from core.models import Conversation, Message, MessageRole
from core.protocols import ChatDatabaseProtocol
from llm.manager import get_llm_manager

from .chat_stream_manager import get_stream_manager

logger = get_logger(__name__)


class ChatService:
    """Chat service class."""

    def __init__(self):
        self.db: ChatDatabaseProtocol = get_db()
        self.llm_manager = get_llm_manager()
        self.stream_manager = get_stream_manager()

    async def create_conversation(
        self,
        title: str,
        related_activity_ids: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        model_id: Optional[str] = None,
    ) -> Conversation:
        """
        Create a new conversation.
        """
        conversation_id = str(uuid.uuid4())
        now = datetime.now()

        metadata = (metadata or {}).copy()
        metadata.setdefault("autoTitle", True)
        metadata.setdefault("titleFinalized", False)
        metadata.setdefault("generatedTitleSource", "default")

        conversation = Conversation(
            id=conversation_id,
            title=title,
            created_at=now,
            updated_at=now,
            related_activity_ids=related_activity_ids or [],
            metadata=metadata or {},
            model_id=model_id,
        )

        # Persist to the database
        self.db.conversations.insert(
            conversation_id=conversation.id,
            title=conversation.title,
            related_activity_ids=conversation.related_activity_ids,
            metadata=conversation.metadata,
            model_id=model_id,
        )

        logger.info(f"âœ… Conversation created: {conversation_id}, title: {title}")
        return conversation

    async def create_conversation_from_activities(
        self, activity_ids: List[str]
    ) -> Dict[str, Any]:
        """
        ä»æ´»åŠ¨åˆ›å»ºå¯¹è¯ï¼Œå¹¶ç”Ÿæˆä¸Šä¸‹æ–‡
        """
        if not activity_ids:
            raise ValueError("æ´»åŠ¨ ID åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # Fetch activity details from the database
        activities = await self.db.activities.get_by_ids(activity_ids)

        title = "å…³äºæ´»åŠ¨çš„è®¨è®º"
        if activities:
            title = f"å…³äº {activities[0].get('title', 'æ´»åŠ¨')} çš„è®¨è®º"

        conversation = await self.create_conversation(
            title=title,
            related_activity_ids=activity_ids,
            metadata={
                "autoTitle": False,
                "titleFinalized": True,
                "generatedTitleSource": "activity_seed",
            },
        )

        context_prompt = self._generate_activity_context_prompt(activities)

        await self.save_message(
            conversation_id=conversation.id, role="system", content=context_prompt
        )

        return {
            "conversationId": conversation.id,
            "title": title,
            "context": context_prompt,
        }

    async def _load_activity_context(self, activity_ids: List[str]) -> Optional[str]:
        """
        ä»æ•°æ®åº“åŠ è½½æ´»åŠ¨è¯¦æƒ…ï¼ˆåŒ…æ‹¬äº‹ä»¶æ‘˜è¦å’Œè¯¦ç»†å†…å®¹ï¼‰å¹¶ç”Ÿæˆä¸Šä¸‹æ–‡
        """
        if not activity_ids:
            logger.warning('âš ï¸ activity_ids is empty; unable to load activity context')
            return None

        try:
            logger.debug(f"ğŸ” Loading activity context for IDs: {activity_ids}")

            activities = []
            for activity_id in activity_ids:
                # Use async repository method with await
                activity_data = await self.db.activities.get_by_id(activity_id)
                if activity_data:
                    activities.append(activity_data)
                    logger.debug(
                        f"  âœ… æ‰¾åˆ°æ´»åŠ¨: {activity_data.get('title', 'Unknown')}"
                    )
                else:
                    logger.warning(f"  âš ï¸ Activity ID not found: {activity_id}")

            if not activities:
                logger.warning('âš ï¸ No activity data found')
                return None

            context_parts = [
                "# æ´»åŠ¨ä¸Šä¸‹æ–‡\n\nç”¨æˆ·æ­£åœ¨è®¨è®ºä»¥ä¸‹æ´»åŠ¨ï¼Œè¯·åŸºäºè¿™äº›æ´»åŠ¨ä¿¡æ¯è¿›è¡Œåˆ†æå’Œå›ç­”ï¼š\n"
            ]

            for activity in activities:
                title = activity.get("title", "æœªå‘½åæ´»åŠ¨")
                description = activity.get("description", "")
                start_time = activity.get("start_time", "")
                end_time = activity.get("end_time", "")

                context_parts.append(f"\n## æ´»åŠ¨ï¼š{title}\n")
                context_parts.append(f"- **æ—¶é—´èŒƒå›´**: {start_time} - {end_time}\n")

                if description:
                    context_parts.append(f"- **æ´»åŠ¨æ€»ç»“**: {description}\n\n")

                # Load event summaries (event_summaries)
                source_event_ids_json = activity.get("source_event_ids", "[]")
                source_event_ids = (
                    json.loads(source_event_ids_json)
                    if isinstance(source_event_ids_json, str)
                    else source_event_ids_json or []
                )

                if source_event_ids:
                    context_parts.append(f"### å…³è”äº‹ä»¶è¯¦æƒ…ï¼ˆå…± {len(source_event_ids)} ä¸ªäº‹ä»¶ï¼‰\n\n")

                    # Load the first 10 event details
                    for i, event_id in enumerate(source_event_ids[:10], 1):
                        event = await self.db.events.get_by_id(event_id)
                        if event:
                            event_title = event.get("title", "")
                            event_summary_text = event.get("summary", "")
                            event_start = event.get("start_time", "")
                            event_end = event.get("end_time", "")

                            # Use the first 50 characters of the summary when no title is available
                            display_title = event_title if event_title else (event_summary_text[:50] + "..." if len(event_summary_text) > 50 else event_summary_text) if event_summary_text else "æœªå‘½åäº‹ä»¶"

                            context_parts.append(f"#### äº‹ä»¶ {i}: {display_title}\n")

                            if event_start and event_end:
                                context_parts.append(f"- æ—¶é—´: {event_start} - {event_end}\n")

                            # Append the event summary content
                            if event_summary_text:
                                context_parts.append(f"- å†…å®¹: {event_summary_text}\n")

                            # Include the description when available
                            event_description = event.get("description", "")
                            if event_description:
                                context_parts.append(f"- è¯¦ç»†æè¿°: {event_description}\n")

                            context_parts.append("\n")

                    if len(source_event_ids) > 10:
                        context_parts.append(f"... è¿˜æœ‰ {len(source_event_ids) - 10} ä¸ªäº‹ä»¶æœªå±•ç¤º\n\n")

            context_parts.append("\n**è¯·åŸºäºä»¥ä¸Šæ´»åŠ¨å’Œäº‹ä»¶çš„è¯¦ç»†ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚**\n")

            context_str = "".join(context_parts)
            logger.debug(f"âœ… Generated activity context, length: {len(context_str)} chars")
            logger.debug(f"Context preview: {context_str[:300]}...")

            return context_str

        except Exception as e:
            logger.error(f"âŒ Failed to load activity context: {e}", exc_info=True)
            return None

    def _generate_activity_context_prompt(
        self, activities: List[Dict[str, Any]]
    ) -> str:
        """
        ç”Ÿæˆæ´»åŠ¨ä¸Šä¸‹æ–‡ prompt
        """
        if not activities:
            return "ç”¨æˆ·å¸Œæœ›è®¨è®ºæœ€è¿‘çš„æ´»åŠ¨ã€‚"

        prompt_parts = ["ç”¨æˆ·åœ¨ä»¥ä¸‹æ—¶é—´æ®µè¿›è¡Œäº†è¿™äº›æ´»åŠ¨ï¼š\n"]

        for activity in activities:
            start_time = activity.get("start_time", "æœªçŸ¥")
            end_time = activity.get("end_time", "æœªçŸ¥")
            title = activity.get("title", "æœªå‘½åæ´»åŠ¨")
            description = activity.get("description", "")

            prompt_parts.append(f"\n[{start_time} - {end_time}] {title}")
            if description:
                prompt_parts.append(f"  {description}")

        prompt_parts.append("\n\nè¯·æ ¹æ®è¿™äº›æ´»åŠ¨æä¾›åˆ†æå’Œå»ºè®®ã€‚")

        return "\n".join(prompt_parts)

    async def save_message(
        self,
        conversation_id: str,
        role: str,
        content: str,
        metadata: Optional[Dict[str, Any]] = None,
        images: Optional[List[str]] = None,
    ) -> Message:
        """
        ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
        """
        message_id = str(uuid.uuid4())
        now = datetime.now()

        message = Message(
            id=message_id,
            conversation_id=conversation_id,
            role=MessageRole(role),
            content=content,
            timestamp=now,
            metadata=metadata or {},
            images=images or [],
        )

        # Persist to the database
        self.db.messages.insert(
            message_id=message.id,
            conversation_id=message.conversation_id,
            role=message.role.value,
            content=message.content,
            timestamp=message.timestamp.isoformat(),
            metadata=message.metadata,
            images=message.images,
        )

        # Update the conversation updated_at column
        self.db.conversations.update(
            conversation_id=conversation_id,
            title=None,  # Leave the title unchanged
        )

        logger.debug(
            f"ä¿å­˜æ¶ˆæ¯: {message_id}, å¯¹è¯: {conversation_id}, è§’è‰²: {role}, å›¾ç‰‡æ•°: {len(images or [])}"
        )
        return message

    async def get_message_history(
        self, conversation_id: str, limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        è·å–å¯¹è¯çš„æ¶ˆæ¯å†å²ï¼ˆç”¨äºLLMä¸Šä¸‹æ–‡ï¼‰
        æ”¯æŒå¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰
        """
        messages = self.db.messages.get_by_conversation(conversation_id, limit=limit)

        llm_messages = []
        for msg in messages:
            # Check whether the message includes images
            images_json = msg.get("images", "[]")
            images = (
                json.loads(images_json)
                if isinstance(images_json, str)
                else images_json or []
            )

            if images:
                # Multimodal message format (OpenAI Vision API)
                content_parts = []

                # Append text content when available
                if msg["content"]:
                    content_parts.append({"type": "text", "text": msg["content"]})

                # Append images
                for image_data in images:
                    content_parts.append(
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_data  # Base64 format: data:image/jpeg;base64,...
                            },
                        }
                    )

                llm_messages.append({"role": msg["role"], "content": content_parts})
            else:
                # Plain-text message
                llm_messages.append({"role": msg["role"], "content": msg["content"]})

        # When few messages exist (first conversation), inject activity context if available
        if len(llm_messages) <= 2:
            logger.debug(
                f"ğŸ” æ£€æŸ¥å¯¹è¯ {conversation_id} æ˜¯å¦æœ‰å…³è”æ´»åŠ¨ï¼ˆæ¶ˆæ¯æ•°: {len(llm_messages)}ï¼‰"
            )
            conversation_data = self.db.conversations.get_by_id(conversation_id)

            if not conversation_data:
                logger.warning(f"âš ï¸ Conversation data not found: {conversation_id}")
            elif not conversation_data.get("related_activity_ids"):
                logger.debug(f"ğŸ“ Conversation {conversation_id} has no linked activities")
            else:
                activity_ids = (
                    json.loads(conversation_data["related_activity_ids"])
                    if isinstance(conversation_data["related_activity_ids"], str)
                    else conversation_data["related_activity_ids"]
                )

                logger.debug(f"ğŸ”— Conversation {conversation_id} linked to activities: {activity_ids}")

                if activity_ids:
                    activity_context = await self._load_activity_context(activity_ids)
                    if activity_context:
                        context_message = {
                            "role": "system",
                            "content": activity_context,
                        }
                        llm_messages.insert(0, context_message)
                        logger.debug(
                            f"âœ… ä¸ºå¯¹è¯ {conversation_id} æ³¨å…¥æ´»åŠ¨ä¸Šä¸‹æ–‡ï¼Œæ´»åŠ¨æ•°é‡: {len(activity_ids)}ï¼Œä¸Šä¸‹æ–‡é•¿åº¦: {len(activity_context)}"
                        )
                    else:
                        logger.warning('âš ï¸ Unable to generate activity context')

        return llm_messages

    # ===== Image processing helpers =====

    async def _convert_image_paths_to_base64(
        self, images: Optional[List[str]] = None
    ) -> Optional[List[str]]:
        """
        Convert image file paths to base64 encoded strings.
        Detects if an image is a file path or already base64/data URL encoded.

        Args:
            images: List of image strings (file paths or base64 data)

        Returns:
            List of base64 encoded image strings
        """
        if not images:
            return images

        processed_images = []
        for image in images:
            # Check if it's already a Data URL (starts with data:)
            if image.startswith("data:"):
                # Already a Data URL, use as-is
                processed_images.append(image)
                logger.debug("Image is already a Data URL, skipping conversion")
            # Check if it looks like a file path (absolute or relative path on filesystem)
            elif (
                ("/" in image or "\\" in image)
                and not image.startswith("http")
                and os.path.exists(image)
            ):
                # Looks like a file path that exists, try to read and convert
                try:
                    with open(image, "rb") as f:
                        file_data = f.read()
                        base64_data = base64.b64encode(file_data).decode("utf-8")
                        processed_images.append(base64_data)
                        logger.debug(f"Converted image file to base64: {image}")
                except Exception as e:
                    logger.error(f"Failed to convert image file {image}: {e}")
            else:
                # Assume it's already base64 encoded (pure base64 string)
                processed_images.append(image)
                logger.debug("Image is already base64 encoded, using as-is")

        return processed_images

    # ===== Agent related helpers =====

    def _detect_agent_command(self, user_message: Optional[str]) -> Optional[str]:
        """
        æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦ä¸ºæ˜¾å¼ Agent å‘½ä»¤ï¼ˆä»¥ '/task' å¼€å¤´ï¼‰ã€‚
        è¿”å›ä»»åŠ¡æè¿°ï¼ˆå»æ‰å‰ç¼€ï¼‰æˆ– Noneã€‚
        """
        if not user_message:
            return None
        text = user_message.strip()
        if text.startswith("/task"):
            desc = text[len("/task") :].strip()
            return desc if desc else None
        return None

    def _select_agent_type(self, task_description: str) -> str:
        """
        ç®€å•å…³é”®è¯è§„åˆ™æ¥å†³å®šåº”è¯¥ä½¿ç”¨å“ªä¸ª Agentã€‚
        ä»¥åå¯æ›¿æ¢ä¸ºæ›´å¤æ‚çš„æ„å›¾æ£€æµ‹/åˆ†ç±»é€»è¾‘ã€‚
        """
        low = (task_description or "").lower()
        if any(k in low for k in ["å†™", "æ–‡ç« ", "æ–‡æ¡£", "åšå®¢", "æŠ¥å‘Š", "å†™ä½œ"]):
            return "WritingAgent"
        if any(k in low for k in ["ç ”ç©¶", "æ”¶é›†", "èµ„æ–™", "è°ƒç ”", "è°ƒæŸ¥"]):
            return "ResearchAgent"
        if any(k in low for k in ["åˆ†æ", "ç»Ÿè®¡", "æ•°æ®", "è¶‹åŠ¿", "è¯„ä¼°"]):
            return "AnalysisAgent"
        return "SimpleAgent"

    async def _handle_agent_task_and_respond(
        self, conversation_id: str, task_desc: str
    ) -> str:
        """
        åˆ›å»º Agent ä»»åŠ¡å¹¶å¯åŠ¨æ‰§è¡Œï¼Œè¿”å›è¦å‘é€åˆ° chat çš„ç¡®è®¤æ–‡æœ¬ã€‚
        ä»»åŠ¡å®é™…åœ¨åå°æ‰§è¡Œï¼Œå‰ç«¯å¯é€šè¿‡ Agent API æˆ–äº‹ä»¶æŸ¥çœ‹è¿›åº¦ä¸ç»“æœã€‚
        """
        agent_type = self._select_agent_type(task_desc)
        try:
            task = task_manager.create_task(agent_type, task_desc)
            logger.debug(
                f"Chat -> åˆ›å»º Agent ä»»åŠ¡: {task.id} agent={agent_type} desc={task_desc}"
            )

            started = await task_manager.execute_task(task.id)
            if started:
                reply = (
                    f"å·²åˆ›å»ºä»»åŠ¡ `{task.id}`ï¼Œç”± `{agent_type}` æ‰§è¡Œã€‚"
                    " ä»»åŠ¡å·²åœ¨åå°å¯åŠ¨ï¼Œä½ å¯ä»¥åœ¨â€œä»»åŠ¡â€é¡µé¢æŸ¥çœ‹è¿›åº¦ä¸ç»“æœã€‚"
                )
            else:
                reply = "ä»»åŠ¡åˆ›å»º/å¯åŠ¨å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        except Exception as e:
            logger.error(f"Chat -> Failed to create/start Agent task: {e}", exc_info=True)
            reply = f"ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼š{str(e)[:200]}"

        # Persist the assistant confirmation and stream it back at once
        try:
            await self.save_message(
                conversation_id=conversation_id, role="assistant", content=reply
            )
        except Exception:
            logger.exception('Failed to save task confirmation message')
        try:
            emit_chat_message_chunk(
                conversation_id=conversation_id, chunk=reply, done=True
            )
        except Exception:
            logger.exception('Failed to send task confirmation event')

        return reply

    async def send_message_stream(
        self,
        conversation_id: str,
        user_message: str,
        images: Optional[List[str]] = None,
        model_id: Optional[str] = None,
    ) -> str:
        """
        å‘é€æ¶ˆæ¯å¹¶æµå¼è¿”å›å“åº”

        æ”¯æŒï¼š
        - æ™®é€š LLM èŠå¤©æµï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        - å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰
        - æ˜¾å¼ Agent å‘½ä»¤ï¼šæ¶ˆæ¯ä»¥ `/task` å¼€å¤´æ—¶ï¼Œåˆ›å»ºå¹¶å¯åŠ¨ Agent ä»»åŠ¡ï¼Œç«‹å³è¿”å›ç¡®è®¤ï¼ˆå¹¶ä¿å­˜ä¸º assistant æ¶ˆæ¯ï¼‰ã€‚

        æ­¤æ–¹æ³•ä¼šåˆ›å»ºä¸€ä¸ªåå°ä»»åŠ¡æ¥å¤„ç†æµå¼è¾“å‡ºï¼Œç¡®ä¿ä¸åŒä¼šè¯ä¹‹é—´çš„æµå¼å¤„ç†äº’ä¸å¹²æ‰°ã€‚
        """
        # Check whether this conversation already has an active streaming task
        if self.stream_manager.is_streaming(conversation_id):
            logger.warning(f"Conversation {conversation_id} already has an active streaming task")
            # We could cancel the old task or reject the new request
            # Here we cancel the old task and start a new one
            self.stream_manager.cancel_stream(conversation_id)

        # Spawn a background task to handle streaming
        task = asyncio.create_task(
            self._process_stream(conversation_id, user_message, images, model_id)
        )

        # Register the task with the stream manager
        self.stream_manager.register_stream(conversation_id, task)

        logger.info(f"âœ… Streaming task started for conversation {conversation_id}")
        return ""  # Return immediately; actual responses stream via events

    async def _process_stream(
        self,
        conversation_id: str,
        user_message: str,
        images: Optional[List[str]] = None,
        model_id: Optional[str] = None,
    ) -> None:
        """
        å¤„ç†æµå¼è¾“å‡ºçš„å®é™…é€»è¾‘ï¼ˆåœ¨åå°ä»»åŠ¡ä¸­è¿è¡Œï¼‰
        """
        # Timeout: 300 seconds (5 minutes)
        TIMEOUT_SECONDS = 300

        try:
            # Process images by converting file paths to base64
            processed_images = await self._convert_image_paths_to_base64(images)

            # 1. Save the user message (including images)
            await self.save_message(
                conversation_id=conversation_id,
                role="user",
                content=user_message,
                images=processed_images,
            )
            self._maybe_update_conversation_title(conversation_id)

            # 1.a Detect explicit Agent commands (/task)
            task_desc = self._detect_agent_command(user_message)
            if task_desc is not None:
                logger.debug(f"Detected /task command, description: {task_desc}")
                await self._handle_agent_task_and_respond(conversation_id, task_desc)
                return

            # 2. Fetch history (may include activity context)
            messages = await self.get_message_history(conversation_id)

            logger.debug(f"ğŸ“ Conversation {conversation_id} message count: {len(messages)}")
            if messages:
                logger.debug(
                    f"ğŸ“ ç¬¬ä¸€æ¡æ¶ˆæ¯è§’è‰²: {messages[0].get('role')}, å†…å®¹é•¿åº¦: {len(messages[0].get('content', ''))}"
                )

            # 2.5 If no system message exists, insert Markdown-format guidance
            if not messages or messages[0].get("role") != "system":
                system_prompt = {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚è¯·ä½¿ç”¨ Markdown æ ¼å¼å›å¤ï¼Œæ³¨æ„ï¼š\n"
                        "- ä½¿ç”¨ `ä»£ç ` è¡¨ç¤ºè¡Œå†…ä»£ç ï¼ˆå•ä¸ªåå¼•å·ï¼‰\n"
                        "- ä½¿ç”¨ ```è¯­è¨€\\nä»£ç å—\\n``` è¡¨ç¤ºå¤šè¡Œä»£ç å—ï¼ˆä¸‰ä¸ªåå¼•å·ï¼‰\n"
                        "- ä½¿ç”¨ **ç²—ä½“** è¡¨ç¤ºå¼ºè°ƒ\n"
                        "- ä½¿ç”¨ - æˆ– 1. è¡¨ç¤ºåˆ—è¡¨\n"
                        "- ä¸è¦åœ¨æ™®é€šæ–‡æœ¬ä¸­ä½¿ç”¨åå¼•å·å­—ç¬¦ï¼Œé™¤éæ˜¯è¡¨ç¤ºä»£ç "
                    ),
                }
                messages.insert(0, system_prompt)
                logger.debug('ğŸ“ Adding Markdown-format guidance system message')

            # Record the messages sent to the LLM
            logger.debug(f"ğŸ¤– Messages sent to the LLM: {len(messages)}")
            for i, msg in enumerate(messages):
                logger.debug(
                    f"  æ¶ˆæ¯ {i}: role={msg.get('role')}, å†…å®¹é•¿åº¦={len(msg.get('content', ''))}"
                )

            # 3. Stream responses from the LLM (with timeout)
            full_response = ""
            is_error_response = False
            try:
                # timeout may not exist when python version < 3.11, but we use python 3.14
                async with asyncio.timeout(TIMEOUT_SECONDS): # type: ignore[attr-defined]
                    async for chunk in self.llm_manager.chat_completion_stream(messages, model_id=model_id):
                        full_response += chunk

                        # Check if chunk contains error pattern (LLM client yields errors as chunks)
                        if chunk.startswith("[Error]") or chunk.startswith("[é”™è¯¯]"):
                            is_error_response = True

                        # Send chunks to the frontend in real time
                        emit_chat_message_chunk(
                            conversation_id=conversation_id, chunk=chunk, done=False
                        )
            except asyncio.TimeoutError:
                error_msg = "Request timeout, please check network connection"
                logger.error(f"âŒ LLM call timed out ({TIMEOUT_SECONDS}s): {conversation_id}")

                # Emit the timeout error with error=True
                await self.save_message(
                    conversation_id=conversation_id,
                    role="assistant",
                    content=error_msg,
                    metadata={"error": True, "error_type": "timeout"},
                )
                emit_chat_message_chunk(
                    conversation_id=conversation_id, chunk=error_msg, done=True, error=True
                )
                return

            # 4. Handle error responses (LLM client yields errors as chunks instead of raising)
            if is_error_response:
                logger.error(f"âŒ LLM returned error response: {full_response[:100]}")
                await self.save_message(
                    conversation_id=conversation_id,
                    role="assistant",
                    content=full_response,
                    metadata={"error": True, "error_type": "llm"},
                )
                emit_chat_message_chunk(
                    conversation_id=conversation_id,
                    chunk=full_response,
                    done=True,
                    error=True,
                )
                return

            # 5. Save the assistant response (normal completion)
            assistant_message = await self.save_message(
                conversation_id=conversation_id, role="assistant", content=full_response
            )
            self._maybe_update_conversation_title(conversation_id)

            # 6. Emit the completion signal
            emit_chat_message_chunk(
                conversation_id=conversation_id,
                chunk="",
                done=True,
                message_id=assistant_message.id,
            )

            logger.debug(
                f"âœ… æµå¼æ¶ˆæ¯å‘é€å®Œæˆ: {conversation_id}, é•¿åº¦: {len(full_response)}"
            )

        except asyncio.CancelledError:
            # Task canceled (e.g., user switched conversations and sent a new message)
            logger.warning(f"âš ï¸ Streaming task canceled for conversation {conversation_id}")
            emit_chat_message_chunk(
                conversation_id=conversation_id,
                chunk="[ä»»åŠ¡å·²å–æ¶ˆ]",
                done=True
            )
            raise

        except Exception as e:
            logger.error(f"Streaming message failed: {e}", exc_info=True)

            # Emit the error signal with error=True
            error_message = f"[é”™è¯¯] {str(e)[:100]}"
            emit_chat_message_chunk(
                conversation_id=conversation_id, chunk=error_message, done=True, error=True
            )

            # Persist the error message
            await self.save_message(
                conversation_id=conversation_id,
                role="assistant",
                content=error_message,
                metadata={"error": True},
            )

    async def get_conversations(
        self, limit: int = 50, offset: int = 0
    ) -> List[Conversation]:
        """
        è·å–å¯¹è¯åˆ—è¡¨
        """
        conversations_data = self.db.conversations.get_all(limit=limit, offset=offset)

        conversations = []
        for data in conversations_data:

            # SQLite CURRENT_TIMESTAMP returns UTC; mark it explicitly
            created_at = datetime.fromisoformat(data["created_at"]).replace(
                tzinfo=timezone.utc
            )
            updated_at = datetime.fromisoformat(data["updated_at"]).replace(
                tzinfo=timezone.utc
            )

            conversation = Conversation(
                id=data["id"],
                title=data["title"],
                created_at=created_at,
                updated_at=updated_at,
                related_activity_ids=self._ensure_json_list(
                    data.get("related_activity_ids")
                ),
                metadata=self._ensure_json_dict(data.get("metadata")),
                model_id=data.get("model_id"),
            )
            conversations.append(conversation)

        return conversations

    async def get_messages(
        self, conversation_id: str, limit: int = 100, offset: int = 0
    ) -> List[Message]:
        """
        è·å–å¯¹è¯çš„æ¶ˆæ¯åˆ—è¡¨
        """
        messages_data = self.db.messages.get_by_conversation(
            conversation_id=conversation_id, limit=limit, offset=offset
        )

        messages = []
        for data in messages_data:

            # SQLite stores timestamps in UTC; treat them explicitly as UTC
            timestamp = datetime.fromisoformat(data["timestamp"]).replace(
                tzinfo=timezone.utc
            )

            message = Message(
                id=data["id"],
                conversation_id=data["conversation_id"],
                role=MessageRole(data["role"]),
                content=data["content"],
                timestamp=timestamp,
                metadata=self._ensure_json_dict(data.get("metadata")),
                images=self._ensure_json_list(data.get("images")),
            )
            messages.append(message)

        return messages

    async def delete_conversation(self, conversation_id: str) -> bool:
        """
        åˆ é™¤å¯¹è¯ï¼ˆçº§è”åˆ é™¤æ¶ˆæ¯ï¼‰
        """
        affected_rows = self.db.conversations.delete(conversation_id)
        if affected_rows > 0:
            logger.info(f"âœ… Conversation deleted: {conversation_id}")
            return True
        else:
            logger.warning(f"Failed to delete conversation (not found): {conversation_id}")
            return False

    # ===== Helper methods =====

    def _ensure_json_list(self, value: Any) -> List[Any]:
        """Ensure the given value is a list (decoded from JSON if needed)."""
        return self._normalize_json_field(value, list)

    def _ensure_json_dict(self, value: Any) -> Dict[str, Any]:
        """Ensure the given value is a dict (decoded from JSON if needed)."""
        return self._normalize_json_field(value, dict)

    def _normalize_json_field(self, value: Any, expected_type: type) -> Any:
        fallback = [] if expected_type is list else {}

        if value is None:
            return fallback

        if expected_type is list and isinstance(value, tuple):
            return list(value)

        if isinstance(value, expected_type):
            return value

        if isinstance(value, str):
            text = value.strip()
            if not text:
                return fallback
            try:
                parsed = json.loads(text)
            except (json.JSONDecodeError, TypeError) as exc:
                logger.warning(
                    "Failed to parse %s JSON field: %s",
                    expected_type.__name__,
                    exc,
                )
                return fallback
            if isinstance(parsed, expected_type):
                return parsed

        logger.warning(
            "Unexpected value for %s JSON field: %r (using default)",
            expected_type.__name__,
            value,
        )
        return fallback

    def _maybe_update_conversation_title(self, conversation_id: str) -> None:
        """Auto-generate a title from the first message."""
        try:
            conversation = self.db.conversations.get_by_id(conversation_id)
            if not conversation:
                return

            current_title = (conversation.get("title") or "").strip()
            metadata_raw = conversation.get("metadata") or {}
            if isinstance(metadata_raw, str):
                try:
                    metadata = json.loads(metadata_raw)
                except json.JSONDecodeError:
                    metadata = {}
            else:
                metadata = metadata_raw

            if not metadata.get("autoTitle", True) or metadata.get("titleFinalized"):
                return

            messages = self.db.messages.get_by_conversation(conversation_id, limit=10, offset=0)

            candidate_text = ""
            for msg in messages:
                text = (msg.get("content") or "").strip()
                if not text:
                    continue
                if msg.get("role") == "user":
                    candidate_text = text
                    break

            if not candidate_text:
                for msg in messages:
                    text = (msg.get("content") or "").strip()
                    if text:
                        candidate_text = text
                        break

            new_title = self._generate_title_from_text(candidate_text)
            if not new_title or new_title == current_title:
                return

            metadata["autoTitle"] = False
            metadata["titleFinalized"] = True
            metadata["generatedTitleSource"] = "auto"
            metadata["generatedTitlePreview"] = new_title
            metadata["generatedTitleAt"] = datetime.now().isoformat()

            self.db.conversations.update(
                conversation_id=conversation_id, title=new_title, metadata=metadata
            )

            logger.debug(f"Auto-generated conversation title: {conversation_id} -> {new_title}")
        except Exception as exc:
            logger.warning(f"Failed to auto-update conversation title: {exc}")

    def _generate_title_from_text(self, text: str, max_length: int = 28) -> str:
        """Extract a short title from raw text."""
        if not text:
            return ""

        cleaned = text.strip()
        cleaned = re.sub(r"```[\s\S]*?```", " ", cleaned)
        cleaned = re.sub(r"`([^`]+)`", r"\1", cleaned)
        cleaned = re.sub(r"^[#>*\-\s]+", "", cleaned)
        cleaned = re.sub(r"\s+", " ", cleaned).strip(" -_")

        if not cleaned:
            return ""

        if len(cleaned) <= max_length:
            return cleaned

        return textwrap.shorten(cleaned, width=max_length, placeholder="â€¦")


# å…¨å±€æœåŠ¡å®ä¾‹
_chat_service: Optional[ChatService] = None


def get_chat_service() -> ChatService:
    """Get the Chat service instance."""
    global _chat_service
    if _chat_service is None:
        _chat_service = ChatService()
    return _chat_service
